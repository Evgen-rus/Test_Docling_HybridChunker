import os
import pathlib

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –∫—ç—à–∞ –¥–ª—è HuggingFace –º–æ–¥–µ–ª–µ–π
def setup_local_cache():
    """
    –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç –ª–æ–∫–∞–ª—å–Ω–æ–µ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ HuggingFace –º–æ–¥–µ–ª–µ–π.
    –°–æ–∑–¥–∞–µ—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –ø–∞–ø–∫–∏ –∏ —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è.
    """
    cache_dir = pathlib.Path("models_cache").absolute()
    cache_dir.mkdir(exist_ok=True)
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è –¥–ª—è HuggingFace
    os.environ["HF_HOME"] = str(cache_dir)
    os.environ["HUGGINGFACE_HUB_CACHE"] = str(cache_dir / "hub")
    os.environ["HF_HUB_DISABLE_SYMLINKS_WARNING"] = "1"
    
    print(f"üîß –ù–∞—Å—Ç—Ä–æ–µ–Ω –ª–æ–∫–∞–ª—å–Ω—ã–π –∫—ç—à HuggingFace: {cache_dir}")
    return cache_dir

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –∫—ç—à–∞ –ø–µ—Ä–µ–¥ –∏–º–ø–æ—Ä—Ç–æ–º –±–∏–±–ª–∏–æ—Ç–µ–∫
cache_path = setup_local_cache()

from docling.document_converter import DocumentConverter
from utils.sitemap import get_sitemap_urls

print("ü§ñ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è DocumentConverter...")
try:
    converter = DocumentConverter()
    print("‚úÖ DocumentConverter —É—Å–ø–µ—à–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω!")
except Exception as e:
    print(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ DocumentConverter: {e}")
    print("üîÑ –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∑–∞–ø—É—Å—Ç–∏—Ç—å —Å–∫—Ä–∏–ø—Ç —Å –ø—Ä–∞–≤–∞–º–∏ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞ –∏–ª–∏ –ø—Ä–æ–≤–µ—Ä—å—Ç–µ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç-—Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ")
    exit(1)

# --------------------------------------------------------------
# –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
# --------------------------------------------------------------

print("üöÄ –ù–∞—á–∏–Ω–∞—é –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞...")
result = converter.convert("documents/–ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è_–ø–æ_–¥–µ—Ñ–µ–∫—Ç–æ—Å–∫–æ–ø–∏–∏_–≤–∞–ª–æ–≤.pdf")

document = result.document
markdown_output = document.export_to_markdown()
json_output = document.export_to_dict()

print("‚úÖ –î–æ–∫—É–º–µ–Ω—Ç —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω!")
print("üìÑ –†–∞–∑–º–µ—Ä –¥–æ–∫—É–º–µ–Ω—Ç–∞:", len(markdown_output), "—Å–∏–º–≤–æ–ª–æ–≤")
print("\n" + "="*50)
print("–ü–†–ï–í–¨–Æ –ò–ó–í–õ–ï–ß–ï–ù–ù–û–ì–û –¢–ï–ö–°–¢–ê:")
print("="*50)
print(markdown_output[:1000] + "...")

# --------------------------------------------------------------
# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
# --------------------------------------------------------------

with open("extracted_content.md", "w", encoding="utf-8") as f:
    f.write(markdown_output)
    
print("\nüìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ —Ñ–∞–π–ª: extracted_content.md")

# --------------------------------------------------------------
# –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã (–∑–∞–∫–æ–º–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω—ã)
# --------------------------------------------------------------

# # Basic PDF extraction
# result = converter.convert("https://arxiv.org/pdf/2408.09869")
# document = result.document
# markdown_output = document.export_to_markdown()
# json_output = document.export_to_dict()
# print(markdown_output)

# # Basic HTML extraction
# result = converter.convert("https://ds4sd.github.io/docling/")
# document = result.document
# markdown_output = document.export_to_markdown()
# print(markdown_output)

# # Scrape multiple pages using the sitemap
# sitemap_urls = get_sitemap_urls("https://ds4sd.github.io/docling/")
# conv_results_iter = converter.convert_all(sitemap_urls)
# docs = []
# for result in conv_results_iter:
#     if result.document:
#         document = result.document
#         docs.append(document)
